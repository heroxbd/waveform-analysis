\section{Summary and discussion}
\label{sec:discussion}

This section will address the burning question: which waveform analysis method should my experiment use?  We surveyed 8 methods, heuristics~(figure~\ref{fig:method}), deconvolution~(figure~\ref{fig:deconv}), neural network~(figure~\ref{fig:cnn-performance}) and regressions(figures~\ref{fig:dcf}--\ref{fig:fsmp-performance}), from the simplest to the most dedicated\footnote{The source codes are available on GitHub \url{https://github.com/heroxbd/waveform-analysis}.}.  To make a choice, we shall investigate the light curve reconstruction precision under different light intensities $\mu$.

\subsection{Performance}

We constrain the candidates by time consumption, algorithm category and $D_\mathrm{w}$.  Figure~\ref{fig:chargesummary} shows the $D_w$ and time consumption summary of all eight methods with the same waveform sample as figure~\ref{fig:method}.
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/summarycharge.pgf}}
    \caption{\label{fig:chargesummary} Performance of algorithms in terms of $D_\mathrm{w}$ and time consumption, evaluated on the same dataset as figure~\ref{fig:method}. Central points are the average results of $\num[retain-unity-mantissa=false]{1e4}$ waveforms from specific $\mu$ values.  Error bars are 5--95 percentiles.  Fitting stands for direct charge fitting. The time consumed by Fitting, MCMC and FSMP include the LucyDDM pre-conditioner's initialization time.  CNN's time consumption is measured for inference in two conditions: GPU\protect\footnotemark~(dashed error bars) and CPU\protect\footnotemark~(solid error bars).  Training a CNN is a one-time job, and its cost is not included in the plot.}
\end{figure}
\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{Graphics card of NVIDIA\textsuperscript{\textregistered} Tesla A100. }
\stepcounter{footnote}\footnotetext{One CPU core of AMD EYPC\texttrademark\ 7742. }

The $D_\mathrm{w}$ performance of waveform shifting, peak finding and Fourier deconvolution are suboptimal.  Like CNN, they are the fastest because no iteration is involved.  LucyDDM and Fitting have $\num{\sim 100}$ iterations, while FSMP has $\num{\sim 1000}$ iterations, making them two orders of magnitudes slower.  The number of iterations and samples $N_s$ can be decreased to trade for speed.  MCMC is too expansive and its principle is not too different from FSMP.  We shall focus on CNN, LucyDDM, Fitting and FSMP in the following.  

The $D_\mathrm{w}$ and RSS dependence on $\mu$ of LucyDDM, Fitting, CNN and FSMP are plotted in figures~\ref{fig:wdistsummary} and \ref{fig:rsssummary}.  When $\mu$ increases the $D_\mathrm{w}$ of different methods approach each other, while the RSS diverges.  Notice that in the qualitative discussion, large $N_\mathrm{PE}$, large light intensity $\mu$ and large pile-ups are used interchangeably.  The $D_\mathrm{w}$ decrease-before-increase behavior is observed in section~\ref{sec:cnn} that with large $N_\mathrm{PE}$ the overall PE times dominate.  It is harder to be good at $D_\mathrm{w}$ and RSS with larger $N_\mathrm{PE}$, but FSMP achieves the best balance.  The Markov chains of FSMP have room for efficiency turning.  Furthermore, implementing it in field-programmable gate array~(FPGA) commonly found in front-end electronics will accelerate waveform analysis and reduce the volume of data acquisition.  It is also interesting whether a neural network can approximate FSMP.
\begin{figure}[H]
  \begin{subfigure}[b]{\textwidth}
    \resizebox{\textwidth}{!}{\input{figures/vs-wdist.pgf}}
    \caption{\label{fig:wdistsummary}Dependence of Wasserstein distance on light intensity.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \resizebox{\textwidth}{!}{\input{figures/vs-rss.pgf}}
    \caption{\label{fig:rsssummary}Dependence of residual sum of squares on light intensity.}
  \end{subfigure}
  \caption{\label{fig:summary}The dependence of $D_\mathrm{w}$~\subref{fig:wdistsummary} and RSS~\subref{fig:rsssummary} on light intensity $\mu$ for typical Cherenkov (left) and scintillation (right) configurations.  Central points, error bars and method abbreviations have the same meaning as figure~\ref{fig:chargesummary}.  With more pile-ups, $D_\mathrm{w}$ tends to converge while RSS diverges.  The pile-up effect is more significant for the Cherenkov case because the time scale of the light curve is narrower. }
\end{figure}

CNN and Fitting are the kings of $D_\mathrm{w}$ and RSS, because their loss functions are chosen accordingly.  It is informative to study the posterior charge distribution that is not related to the loss function of any method.

\subsection{Charge fidelity and sparsity}

All the discussed methods output $\hat{q}_i$ as the inferred charge of the PE at $t_i'$.  Evident in figure~\ref{fig:recchargehist}, FSMP retains the true charge distribution.  It is the only method modeling PE correctly.

In contrast, LucyDDM, Fitting and CNN distributions are severely distorted.  During the optimization process of $D_\mathrm{w}$ or RSS, $N_s$~(the number of $q_i$) is a constant. Many $\hat{q}_i$ are inferred to be fragmented values.  Retaining charge distribution is a manifestation of sparsity.  FSMP has the best sparsity because it chooses a PE configuration $\bm{z}$ before fitting $\hat{q}_i$.  CNN is somehow better than Fitting, although the latter in theory has self-regulated sparsity.  It is interesting to notice, but the mechanism is unknown to us.

\begin{figure}[H]
  \centering
  \resizebox{0.6\textwidth}{!}{\input{figures/recchargehist.pgf}}
  \caption{\label{fig:recchargehist} $\hat{q}_i$ distributions on the same waveform dataset as figure~\ref{fig:method}.  Method abbreviations are defined in figure~\ref{fig:chargesummary}. ``ChargePDF'' is the charge distribution of simulation input in section~\ref{subsec:spe}. The cut-off near 0 in LucyDDM is an artifact of thresholding in eq.~\eqref{eq:fdconv2}.}
\end{figure}

For large $N_\mathrm{PE}$, the sparsity condition is by definition lost.  The equivalence of charge fidelity and sparsity implies that FSMP performs similarly to others for these cases, as we shall see in the following sections.

\subsection{Inference of incident light}
\label{subsec:timeresolution}

As figure~\ref{fig:summary}, we show the dependence on $\mu$ of bias~(figure~\ref{fig:biasmethods}) and resolution~(figure~\ref{fig:deltamethods}) for different time estimators in the two typical experimental setups.  From figure~\ref{fig:biasmethods}, we see that the $t_0$ estimation biases are all similar to that of $\hat{t}_\mathrm{ALL}$. The bias for the scintillation configuration~(right of figure~\ref{fig:biasmethods}) for small $\mu$ is intrinsic for MLE of exponential distributions.  We can modify it into an unbiased estimator, but leave this discussion to event reconstruction.

People often argue from difficulties for large pile-ups that waveform analysis is unnecessary.  Comparing figures~\ref{fig:reso-diff} and \ref{fig:deltamethods}, it is a myth.  Although $\hat{t}_\mathrm{1st}$ is more precise for large light intensity, all the waveform analysis methods provide magnificently better time resolutions than $\hat{t}_\mathrm{1st}$, more than twice for $\mu>20$ in Cherenkov setup.  FSMP gives the most significant boost.  Such improvement in time resolutions amounts to the position resolution, which benefits fiducial volume, exposure and position-dependent energy bias.

The message is clear from figure~\ref{fig:deltamethods}: any PMT-based experiment that relies on time with PMT occupancy $\mu$ larger than 3 should employ waveform analysis.

\begin{figure}[H]
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-bias.pgf}}
    \caption{\label{fig:biasmethods} Sample average of time reconstruction biases $\overline{\Delta t}$, where $\Delta t = \hat{t} - t_0$.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-deltamethodsdiv.pgf}}
    \caption{\label{fig:deltamethods} Ratios of resolution $\sigma_{\hat{t}_0}/\sigma_{\mathrm{ALL}}$ for time reconstruction. ``1st'' is a reproduction of figure~\ref{fig:reso-diff}.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-biasmu.pgf}}
    \caption{\label{fig:biasmu} Relative sample average of intensity reconstruction biases $\frac{\overline{\Delta \mu}}{\mu}$, where $\Delta \mu = \hat{\mu} - \mu$.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-deltamethodsdivmu.pgf}}
    \caption{\label{fig:deltamu} Ratios of resolution $\frac{\sigma_{\hat{\mu}}}{\underline{\sigma}_\mu}\left(1 + \frac{\overline{\Delta \mu}}{\mu}\right)$ for intensity reconstruction.  The factor $1 + \frac{\overline{\Delta \mu}}{\mu}$ neutralizes biases of $\hat{\mu}$.}
  \end{subfigure}
  \caption{Incident light analysis results for the two typical cases of Cherenkov~(left) and scintillation~(right).  ``ALL'' and ``1st'' are the $\hat{t}_\mathrm{ALL}$ estimator defined in eq.~\eqref{eq:2}. ``int'' is the $\hat{\mu}_Q$ by eq.~\eqref{eq:mu-q}.  LucyDDM, Fitting, CNN use eqs.~\eqref{eq:pseudo} and \eqref{eq:pseudo-mu}.  FSMP has its own natural $\hat{t}_0$ and $\hat{\mu}$ estimators in eq.~\eqref{eq:fsmpcharge}. $\underline{\sigma}_\mu = \sqrt{\mu}$ is the lower bound of intensity resolution~(section~\ref{sec:intensity-mu}). Error bars are 5--95 percentiles.}
\end{figure}

In contrast to time, inference of light intensity uses empty waveforms as well.  We append the waveform samples by $10^4 \times e^{-\mu} / (1-e^{-\mu})$ empty ones.  The number is proportional to the Poisson prediction.  It is equivalent to appending the same amount of zeros to the $\hat{\mu}$'s. The QDC integration estimator $\hat{\mu}_Q$~(``int'' in figures~\ref{fig:biasmu} and~\ref{fig:deltamu}) is ubiquitous and is plotted together with the four waveform analysis methods.

In figure~\ref{fig:biasmu}, the biases of $\hat{\mu}$ of the four methods are within \SI{2}{\percent} and disappear for large $\mu$ expect LucyDDM.  The tendency of LucyDDM comes from the thresholding and scaling in eq.~\eqref{eq:fdconv2}.  For low $\mu$, the upward bias of FSMP and Fitting is due to PE granularity.  The charge $q$ of one PE can fluctuate close to 2 or 0, but eqs.~\eqref{eq:gd-q} and \eqref{eq:fsmpcharge} favor 2 more than 0 in waveforms.  We shall leave the amendment of the bias to event reconstruction in our subsequent publications.

For large $\mu$ the four methods are similar in intensity resolution to $\hat{\mu}_Q$~(figure~\ref{fig:deltamu}).  The resolution ratios of them all approach $1.03 = \sqrt{1 + 0.25^2}$, consistent with eq.~\eqref{eq:energy} if white noise is ignored.  For small $\mu$, FSMP gives the best resolution by correctly modeling charge distributions, as predicted in figure~\ref{fig:recchargehist}.  Like the hit estimator $\hat{\mu}_\mathrm{hit}$ in section~\ref{sec:intensity-mu}, it eliminates the influence of $\sigma_\mathrm{q}$ and $\sigma_\epsilon$ in eq.~\eqref{eq:energy}.  But unlike $\hat{\mu}_\mathrm{hit}$, FSMP also works well for a few PEs.  More importantly, it provides a smooth transition from the ``hit mode'' to the ``charge mode'' with the best intensity resolution of all.   In the scintillation case of figure~\ref{fig:deltamu}, FSMP approaches the resolution lower bound $\underline{\sigma}_\mu$ set by the PE truths for $\mu < 5$, which is the ultimate waveform analysis in that we can hardly do any better.

In the fluid-based neutrino and dark matter experiments, $\mu < 5$ is the sweet spot for \si{MeV} and \si{keV} physics respectively.  The intensity resolution boost in figure~\ref{fig:deltamu} converts directly into energy resolution.  It varies depending on PMT models for different $\sigma_\mathrm{q}$ and $\sigma_\epsilon$.  In our scintillation setup, the improvement is up to $\times 1.04$~(figure~\ref{fig:deltamu}) . Good waveform analysis has the potential to accelerate discovery and broaden the physics reach of existing detectors. 