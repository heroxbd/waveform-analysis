\section{Summary and discussion}
\label{sec:discussion}

This section will address the burning question: which waveform analysis method should my experiment use?  We surveyed 8 methods, heuristics~(figure~\ref{fig:method}), deconvolution~(figure~\ref{fig:deconv}), neural network~(figure~\ref{fig:cnn-performance}) and regressions(figures~\ref{fig:dcf}--\ref{fig:fsmp-performance}), from the simplest to the most dedicated\footnote{The source codes are available on GitHub \url{https://github.com/heroxbd/waveform-analysis}.}.  To make a choice, we shall investigate the light curve reconstruction precision under different light intensities $\mu$.

\subsection{Performance}

We constrain the candidates by time consumption, algorithm category and $D_\mathrm{w}$.  Figure~\ref{fig:chargesummary} shows the $D_\mathrm{w}$ and time consumption summary of all eight methods with the same waveform sample as figure~\ref{fig:method}.
\begin{figure}[H]
    \centering
    \resizebox{0.9\textwidth}{!}{\input{figures/summarycharge.pgf}}
    \caption{\label{fig:chargesummary} Performance of algorithms in terms of $D_\mathrm{w}$ and time consumption, evaluated on the same dataset as figure~\ref{fig:method}. Central points are the average results of $\num[retain-unity-mantissa=false]{1e4}$ waveforms from specific $\mu$ values.  Error bars are 5--95 percentiles.  Fitting stands for direct charge fitting. The time consumed by Fitting, HMC and FSMP include the LucyDDM pre-conditioner's initialization time.  CNN's time consumption is measured for inference in two conditions: GPU\protect\footnotemark~(dashed error bars) and CPU\protect\footnotemark~(solid error bars).  Training a CNN is a one-time job, and its cost is not included in the plot.}
\end{figure}
\addtocounter{footnote}{-2}
\stepcounter{footnote}\footnotetext{One NVIDIA\textsuperscript{\textregistered} A100 GPU (40GB PCIe). }
\stepcounter{footnote}\footnotetext{One CPU core of AMD EYPC\texttrademark\ 7742. }

The $D_\mathrm{w}$ performance of waveform shifting, peak finding and Fourier deconvolution are suboptimal.  Like CNN, they are the fastest because no iteration is involved.  Fitting has $\num{\sim 100}$ iterations, while LucyDDM and FSMP have $\num{\sim 1000}$ iterations, making them 1-2 orders of magnitudes slower.  HMC is too expansive and its principle is not too different from FSMP.  We shall focus on CNN, LucyDDM, Fitting and FSMP in the following.  

The $D_\mathrm{w}$ and RSS dependence on $\mu$ of LucyDDM, Fitting, CNN and FSMP are plotted in figures~\ref{fig:wdistsummary} and \ref{fig:rsssummary}.  When $\mu$ increases the $D_\mathrm{w}$ of different methods approach each other, while the RSS diverges.  Notice that in the qualitative discussion, large $N_\mathrm{PE}$, large light intensity $\mu$ and large pile-ups are used interchangeably.  The $D_\mathrm{w}$ decrease-before-increase behavior is observed in section~\ref{sec:cnn} that with large $N_\mathrm{PE}$ the overall PE times dominate.  It is harder to be good at $D_\mathrm{w}$ and RSS with larger $N_\mathrm{PE}$, but FSMP achieves the best balance.  The Markov chains of FSMP have room for efficiency tuning.  Furthermore, implementing it in field-programmable gate array~(FPGA) commonly found in front-end electronics will accelerate waveform analysis and reduce the volume of data acquisition.  It is also interesting whether a neural network can approximate FSMP.
\begin{figure}[H]
  \begin{subfigure}[b]{\textwidth}
    \resizebox{\textwidth}{!}{\input{figures/vs-wdist.pgf}}
    \caption{\label{fig:wdistsummary}Dependence of Wasserstein distance on light intensity.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \resizebox{\textwidth}{!}{\input{figures/vs-rss.pgf}}
    \caption{\label{fig:rsssummary}Dependence of residual sum of squares on light intensity.}
  \end{subfigure}
  \caption{\label{fig:summary}The dependence of $D_\mathrm{w}$~\subref{fig:wdistsummary} and RSS~\subref{fig:rsssummary} on light intensity $\mu$ for typical Cherenkov (left) and scintillation (right) configurations.  Central points, error bars and method abbreviations have the same meaning as figure~\ref{fig:chargesummary}.  With more pile-ups, $D_\mathrm{w}$ tends to converge while RSS diverges.  The pile-up effect is more significant for the Cherenkov case because the time scale of the light curve is narrower. }
\end{figure}

CNN and Fitting are the kings of $D_\mathrm{w}$ and RSS, because their loss functions are chosen accordingly.  It is informative to study the $\hat{q}_i$ distribution that is not related to the loss function of any method.

\subsection{Charge fidelity and sparsity}
\label{sec:sparsity}

All the discussed methods output $\hat{q}_i$ as the inferred charge of the PE at $t_i'$.  Evident in figure~\ref{fig:recchargehist}, FSMP retains the true charge distribution.  It is the only method modeling PE correctly.

In contrast, LucyDDM, Fitting and CNN distributions are severely distorted.  During the optimization process of $D_\mathrm{w}$ or RSS, $N_\mathrm{s}$ is a constant. Many $\hat{q}_i$ are inferred to be fragmented values.  Retaining charge distribution is a manifestation of sparsity.  FSMP has the best sparsity because it chooses a PE configuration $\bm{z}$ before fitting $\hat{q}_i$.  Since CNN is $D_\mathrm{w}$ orientated discussed in section~\ref{sec:cnn}, it is better than fitting, although the latter has self-regulated sparsity in theory.

\begin{figure}[H]
  \centering
  \resizebox{0.6\textwidth}{!}{\input{figures/recchargehist.pgf}}
  \caption{\label{fig:recchargehist} $\hat{q}_i$ distributions on the same waveform dataset as figure~\ref{fig:method}.  Method abbreviations are defined in figure~\ref{fig:chargesummary}. ``ChargePDF'' is the charge distribution of simulation input in section~\ref{subsec:spe}. The cut-off near 0 in LucyDDM is an artifact of thresholding in eq.~\eqref{eq:fdconv2}.}
\end{figure}

For large $N_\mathrm{PE}$, the sparsity condition is by definition lost.  The equivalence of charge fidelity and sparsity implies that FSMP performs similarly to others for these cases, as we shall see in the following sections.

\subsection{Inference of incident light}
\label{subsec:timeresolution}

As figure~\ref{fig:summary}, we show the dependence on $\mu$ of bias~(figure~\ref{fig:biasmethods}) and resolution~(figure~\ref{fig:deltamethods}) for different time estimators in the two typical experimental setups.  From figure~\ref{fig:biasmethods}, we see that the $t_0$ estimation biases are all similar to that of $\hat{t}_\mathrm{ALL}$.  In the right of figure~\ref{fig:biasmethods}, the biases of LucyDDM, Fitting and CNN for the scintillation configuration at small $\mu$ are intrinsic in exponential-distributed MLEs.  Conversely, the FSMP $t_0$ estimator of eq.~\eqref{eq:fsmpcharge} is unbiased by constructing from samples in the Markov chain.

People often argue from difficulties for large pile-ups that waveform analysis is unnecessary.  Comparing figures~\ref{fig:reso-diff} and \ref{fig:deltamethods}, it is a myth.  Although $\hat{t}_\mathrm{1st}$ is more precise for large light intensity, all the waveform analysis methods provide magnificently better time resolutions than $\hat{t}_\mathrm{1st}$, more than twice for $\mu>20$ in Cherenkov setup.  FSMP gives the most significant boost.  Such improvement in time resolution amounts to the position resolution, which benefits fiducial volume, exposure and position-dependent energy bias.

The message is clear from figure~\ref{fig:deltamethods}: any PMT-based experiment that relies on time with PMT occupancy $\mu$ larger than 3 should employ waveform analysis.

\begin{figure}[H]
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{0.99\textwidth}{!}{\input{figures/vs-biast0.pgf}}
    \vspace{-0.5em}
    \caption{\label{fig:biasmethods} Sample average estimations of time-reconstruction biases $\E[\hat{t} - t_0]$.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{0.99\textwidth}{!}{\input{figures/vs-sigmat0-r.pgf}}
    \vspace{-0.5em}
    \caption{\label{fig:deltamethods} Sample variance estimations of time-resolution ratios $\sqrt{\frac{\Var[\hat{t} - t_0]}{\Var[\hat{t}_\mathrm{ALL} - t_0]}}$. ``1st'' is a reproduction of figure~\ref{fig:reso-diff}.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{0.99\textwidth}{!}{\input{figures/vs-biasmu-r.pgf}}
    \vspace{-0.5em}
    \caption{\label{fig:biasmu} Sample average estimation of intensity-reconstruction biases $\frac{\E[\hat{\mu} - \mu]}{\mu}$.}
  \end{subfigure}

  \vspace{0.5em}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \resizebox{0.99\textwidth}{!}{\input{figures/vs-sigmamu-r.pgf}}
    \vspace{-0.5em}
    \caption{\label{fig:deltamu} Sample variance estimation of intensity-resolution ratios $\frac{\sqrt{\Var[\hat{\mu}]} / \E[\hat{\mu}]}{\sqrt{\Var[N_\mathrm{PE}]} / \E[N_\mathrm{PE}]}$.}
  \end{subfigure}
  \caption{Incident light analysis results for the two typical cases of Cherenkov~(left) and scintillation~(right).  ``ALL'' and ``1st'' are the $\hat{t}_\mathrm{ALL}$ estimator defined in eq.~\eqref{eq:2}. ``int'' is the $\hat{\mu}_Q$ by eq.~\eqref{eq:mu-q}.  LucyDDM, Fitting, CNN use eqs.~\eqref{eq:pseudo} and \eqref{eq:pseudo-mu}.  FSMP has its own natural $\hat{t}_0$ and $\hat{\mu}$ estimators in eq.~\eqref{eq:fsmpcharge}. Error bars are 5--95 percentiles calculated from $t$~(figures~\ref{fig:biasmethods} and \ref{fig:biasmu}), $F$~\subref{fig:deltamethods} and $\chi^2$~\subref{fig:deltamu} statistics.}
\end{figure}

In contrast to time, inference of light intensity uses empty waveforms as well.  We append the waveform samples by $10^4 \times e^{-\mu} / (1-e^{-\mu})$ empty ones.  The number is proportional to the Poisson prediction.  It is equivalent to appending the same amount of zeros to the $\hat{\mu}$'s. The QDC integration estimator $\hat{\mu}_Q$~(``int'' in figures~\ref{fig:biasmu} and~\ref{fig:deltamu}) is ubiquitous and is plotted together with the four waveform analysis methods.

In figure~\ref{fig:biasmu}, the biases of $\hat{\mu}$ of the four methods are within \SI{6}{\percent} and disappear for large $\mu$ expect LucyDDM.  The tendency of LucyDDM comes from the thresholding and scaling in eq.~\eqref{eq:fdconv2}.  For low $\mu$, the upward bias of FSMP and Fitting is due to PE granularity.  The charge $q$ of one PE can fluctuate close to 2 or 0, but eqs.~\eqref{eq:gd-q} and \eqref{eq:fsmpcharge} favor 2 more than 0 in waveforms.  We shall leave the amendment of the bias to event reconstruction in our subsequent publications.

For large $\mu$ the four methods are similar in intensity resolution to $\hat{\mu}_Q$~(figure~\ref{fig:deltamu}).  The resolution ratios of them all approach $1.08 = \sqrt{1 + 0.4^2}$, consistent with eq.~\eqref{eq:energy} if white noise is ignored.  For small $\mu$, FSMP gives the best resolution by correctly modeling charge distributions, as predicted in figure~\ref{fig:recchargehist}.  Like the hit estimator $\hat{\mu}_\mathrm{hit}$ in section~\ref{sec:intensity-mu}, it eliminates the influence of $\Var[q]$ and $\Var[\epsilon]$ in eq.~\eqref{eq:energy}.  But unlike $\hat{\mu}_\mathrm{hit}$, FSMP also works well for a few PEs.  More importantly, it provides a smooth transition from the photon-counting mode to the analog mode with the best intensity resolution of all.   In the scintillation case of figure~\ref{fig:deltamu}, FSMP approaches the resolution lower bound $\Var[N_\mathrm{PE}]$ set by the PE truths for $\mu < 5$, which is the ultimate waveform analysis in that we can hardly do any better.

In the fluid-based neutrino and dark matter experiments, $\mu < 5$ is the sweet spot for \si{MeV} and \si{keV} physics respectively.  The intensity resolution boost in figure~\ref{fig:deltamu} converts directly into energy resolution.  It varies depending on PMT models for different $\Var[q]$ and $\Var[\epsilon]$.  In our scintillation setup, the improvement is up to $\times 1.07$~(figure~\ref{fig:deltamu}) . Good waveform analysis has the potential to accelerate discovery and broaden the physics reach of existing detectors. 